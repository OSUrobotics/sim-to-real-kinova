{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9fd8e4e",
   "metadata": {},
   "source": [
    "# Real world replay buffer\n",
    "\n",
    "\n",
    "### Goal of this file: Make a transfer process to load our actions with the replay buffer given by DDPG algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa36a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# reloads imported files. you're welcome\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f389e538",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb382018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sci\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# generic packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# our packages\n",
    "from utils import state_dim_setup, lerp\n",
    "from buffer import ReplayBuffer_Queue\n",
    "from DDPGfD import DDPGfD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75cec0",
   "metadata": {},
   "source": [
    "### Constants / inputs\n",
    "\n",
    "1. real world experiment directory\n",
    "2. load successes only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d2558e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dir = 'real_positional_test_v6_constant'\n",
    "load_success_only = False\n",
    "state_idx_arr = state_dim_setup('adam_sim2real_v02')\n",
    "state_idx_arr = state_dim_setup('adam_sim2real')  # TODO: yeet this shit once we get the new policy\n",
    "trained_policy_path = 'policies/state_dim_full_train_v01/_07_22_21_0544/policy/train_DDPGfD_kinovaGrip'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144ccdd",
   "metadata": {},
   "source": [
    "### Loading replay buffer stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c04aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add relative directory\n",
    "assert Path(real_dir).exists(), 'Check that the real log directory ' + real_dir + ' exists.'\n",
    "\n",
    "\n",
    "episode_dir = os.path.join(real_dir, 'episodes/')\n",
    "\n",
    "# get filepaths from episodes directory.\n",
    "reward_filepaths = sorted(glob.glob(os.path.join(episode_dir, 'reward*.npy')))\n",
    "obs_filepaths = sorted(glob.glob(os.path.join(episode_dir, 'obs*.npy')))\n",
    "next_obs_filepaths = sorted(glob.glob(os.path.join(episode_dir, 'next_obs*.npy')))\n",
    "action_filepaths = sorted(glob.glob(os.path.join(episode_dir, 'action*.npy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20d4f773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 30, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_arr = np.array([np.load(filepath) for filepath in reward_filepaths])\n",
    "obs_arr = np.array([np.load(filepath) for filepath in obs_filepaths])\n",
    "next_obs_arr = np.array([np.load(filepath) for filepath in next_obs_filepaths])\n",
    "action_arr = np.array([np.load(filepath) for filepath in action_filepaths])\n",
    "\n",
    "# lerp the actions to the simulator range\n",
    "action_arr = lerp(action_arr, old_min=0, old_max=3400, new_min=0, new_max=1.5)\n",
    "action_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f2dea",
   "metadata": {},
   "source": [
    "### Cleaning episode length\n",
    "\n",
    "Note: I forgot to add a `done` variable, so uhhh we're gonna just check when our finger action goes to 0 LOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c8eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first index of each episode where all the actions are 0.\n",
    "stop_index_arr = np.argmax(np.all(action_arr==0, axis=-1), axis=-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e4e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_action = [action_arr[eps_idx, :stop_index] for eps_idx, stop_index in enumerate(stop_index_arr)]\n",
    "cut_reward = [np.concatenate((reward_arr[eps_idx, :stop_index-1], reward_arr[eps_idx, -1].reshape((1,)))) for eps_idx, stop_index in enumerate(stop_index_arr)] # set the last index to be successful based on the last timestep. We do this because we put the reward at the very end of the episode LOL\n",
    "cut_obs = [obs_arr[eps_idx, :stop_index] for eps_idx, stop_index in enumerate(stop_index_arr)]\n",
    "cut_next_obs = [next_obs_arr[eps_idx, :stop_index] for eps_idx, stop_index in enumerate(stop_index_arr)]\n",
    "\n",
    "cut_dones = [np.concatenate((np.zeros((len(eps_arr) - 1,)), np.array([1]))) for eps_arr in cut_reward]\n",
    "cut_not_dones = [np.concatenate((np.ones((len(eps_arr) - 1,)), np.array([0]))) for eps_arr in cut_reward]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd83bc",
   "metadata": {},
   "source": [
    "### Feeding replay buffer into Queue-based Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29dafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the thing LOL\n",
    "replay_buffer = ReplayBuffer_Queue(state_dim=len(state_idx_arr), action_dim=3, max_episode=100, n_steps=5)\n",
    "\n",
    "# feed the cookie monster\n",
    "\n",
    "# max_episode: Maximum number of episodes, limit to when we remove old episodes\n",
    "# size: Full size of the replay buffer (number of entries over all episodes)\n",
    "# episodes_count: Number of episodes that have occurred (may be more than max replay buffer side)\n",
    "# replay_ep_num: Number of episodes currently in the replay buffer\n",
    "\n",
    "replay_buffer.store_from_replay_buffer(cut_obs, cut_action, cut_next_obs, cut_reward, cut_not_dones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df3b9b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_action)\n",
    "cut_action[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091ad30",
   "metadata": {},
   "source": [
    "### Loading our pretrained policy\n",
    "\n",
    "### TODO: move constant settings for batch_size, n, discount, tau, expert sampling prop => up to the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa615eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================ INITTING DDPGfD with state dim of:  31 ===============================\n",
      "burh 34\n"
     ]
    }
   ],
   "source": [
    "modified_state_dim = len(state_idx_arr)\n",
    "\n",
    "kwargs = {\n",
    "#     \"state_dim\": modified_state_dim,\n",
    "    \"state_dim\": 31,  # TODO: get rid of this hideous shit\n",
    "    \"action_dim\": 3,\n",
    "    \"max_action\": 1.5,\n",
    "    \"batch_size\": 4,\n",
    "    \"n\": 5,\n",
    "    \"discount\": 0.995,\n",
    "    \"tau\": 0.0005,\n",
    "    \"expert_sampling_proportion\": 1.0\n",
    "}\n",
    "\n",
    "policy = DDPGfD(**kwargs)\n",
    "\n",
    "policy.load(trained_policy_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c576f",
   "metadata": {},
   "source": [
    "### Feeding the replay buffer into pretrained policy (and pray that policy distribution shift doesn't fuck things up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1a34755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 5, 26])\n",
      "pain\n",
      "torch.Size([34, 29])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-86337875206b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m actor_loss, critic_loss, critic_L1loss, critic_LNloss = policy.train_batch_state_already_reduced(episode_num=0, update_count=0,\n\u001b[1;32m     11\u001b[0m                                                                      \u001b[0mexpert_replay_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                                      replay_buffer=None)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sim-to-real-kinova/src/sim-to-real-kinova-master/openai_gym_kinova/src/DDPGfD.py\u001b[0m in \u001b[0;36mtrain_batch_state_already_reduced\u001b[0;34m(self, episode_num, update_count, expert_replay_buffer, replay_buffer)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# print(\"Target Q\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mtarget_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0;31m# assert target_Q.shape == (assert_batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kinova_venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sim-to-real-kinova/src/sim-to-real-kinova-master/openai_gym_kinova/src/DDPGfD.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pain\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_state_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_state_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_q_value\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kinova_venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kinova_venv/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kinova_venv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "# NOTE: max_episode_num doesn't even get used\n",
    "# episode_num is supposed to be set by an outside loop. what the fuck\n",
    "# idk what update_count does. whatever\n",
    "\n",
    "# actor_loss, critic_loss, critic_L1loss, critic_LNloss = policy.train_batch(max_episode_num=420, episode_num=0, update_count=0,\n",
    "#                                                                      expert_replay_buffer=replay_buffer,\n",
    "#                                                                      replay_buffer=None, mod_state_idx=state_idx_arr)\n",
    "\n",
    "# fun: we need to modify so it can train with an already reduced state space\n",
    "actor_loss, critic_loss, critic_L1loss, critic_LNloss = policy.train_batch_state_already_reduced(episode_num=0, update_count=0,\n",
    "                                                                     expert_replay_buffer=replay_buffer,\n",
    "                                                                     replay_buffer=None)\n",
    "\n",
    "\n",
    "# okay the bug is happening because my state dimensions don't match.\n",
    "# we can't fix this one until we're done training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18e7c932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0481,  0.0128,  0.0191,  ...,  0.1101,  0.1260,  0.1237]],\n",
       " \n",
       "         [[-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0481,  0.0128,  0.0191,  ...,  0.1101,  0.1260,  0.1237],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245]],\n",
       " \n",
       "         [[-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0481,  0.0128,  0.0191,  ...,  0.1101,  0.1260,  0.1237],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0477,  0.0136,  0.0191,  ...,  0.1016,  0.1209,  0.1191],\n",
       "          [-0.0487,  0.0149,  0.0173,  ...,  0.1030,  0.1196,  0.1160],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100]],\n",
       " \n",
       "         [[-0.0487,  0.0149,  0.0173,  ...,  0.1030,  0.1196,  0.1160],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100]],\n",
       " \n",
       "         [[-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100]]]),\n",
       " tensor([[[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]],\n",
       " \n",
       "         [[1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000],\n",
       "          [1.5000, 1.5000, 1.5000]]], device='cuda:0'),\n",
       " tensor([[[-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0481,  0.0128,  0.0191,  ...,  0.1101,  0.1260,  0.1237],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245]],\n",
       " \n",
       "         [[-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0481,  0.0128,  0.0191,  ...,  0.1101,  0.1260,  0.1237],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245]],\n",
       " \n",
       "         [[-0.0484,  0.0132,  0.0186,  ...,  0.1113,  0.1272,  0.1243],\n",
       "          [-0.0481,  0.0128,  0.0191,  ...,  0.1101,  0.1260,  0.1237],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245],\n",
       "          [-0.0482,  0.0129,  0.0192,  ...,  0.1115,  0.1272,  0.1245]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0487,  0.0149,  0.0173,  ...,  0.1030,  0.1196,  0.1160],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100]],\n",
       " \n",
       "         [[-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100]],\n",
       " \n",
       "         [[-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0458,  0.0165,  0.0189,  ...,  0.1014,  0.1166,  0.1100],\n",
       "          [-0.0361,  0.0258,  0.0156,  ...,  0.0962,  0.0925,  0.0690]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 0.]], device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing block\n",
    "\"\"\"\n",
    "# sample from the replay buffer\n",
    "replay_buffer.sample_batch_nstep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c444dea",
   "metadata": {},
   "source": [
    "### Save the pretrained policy to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b335a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dir = 'policies/'\n",
    "\n",
    "policy_save_basepath = os.path.join(policy_dir, 'real_world_trained')\n",
    "\n",
    "policy.save(policy_save_basepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
